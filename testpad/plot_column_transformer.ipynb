{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Column Transformer with Heterogeneous Data Sources\n",
        "\n",
        "Datasets can often contain components that require different feature\n",
        "extraction and processing pipelines. This scenario might occur when:\n",
        "\n",
        "1. your dataset consists of heterogeneous data types (e.g. raster images and\n",
        "   text captions),\n",
        "2. your dataset is stored in a :class:`pandas.DataFrame` and different columns\n",
        "   require different processing pipelines.\n",
        "\n",
        "This example demonstrates how to use\n",
        ":class:`~sklearn.compose.ColumnTransformer` on a dataset containing\n",
        "different types of features. The choice of features is not particularly\n",
        "helpful, but serves to illustrate the technique.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Matt Terry <matt.terry@gmail.com>\n",
        "#\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 20 newsgroups dataset\n",
        "\n",
        "We will use the `20 newsgroups dataset <20newsgroups_dataset>`, which\n",
        "comprises posts from newsgroups on 20 topics. This dataset is split\n",
        "into train and test subsets based on messages posted before and after\n",
        "a specific date. We will only use posts from 2 categories to speed up running\n",
        "time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "categories = [\"sci.med\", \"sci.space\"]\n",
        "X_train, y_train = fetch_20newsgroups(\n",
        "    random_state=1,\n",
        "    subset=\"train\",\n",
        "    categories=categories,\n",
        "    remove=(\"footers\", \"quotes\"),\n",
        "    return_X_y=True,\n",
        ")\n",
        "X_test, y_test = fetch_20newsgroups(\n",
        "    random_state=1,\n",
        "    subset=\"test\",\n",
        "    categories=categories,\n",
        "    remove=(\"footers\", \"quotes\"),\n",
        "    return_X_y=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each feature comprises meta information about that post, such as the subject,\n",
        "and the body of the news post.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From: mccall@mksol.dseg.ti.com (fred j mccall 575-3539)\n",
            "Subject: Re: Metric vs English\n",
            "Article-I.D.: mksol.1993Apr6.131900.8407\n",
            "Organization: Texas Instruments Inc\n",
            "Lines: 31\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "American, perhaps, but nothing military about it.  I learned (mostly)\n",
            "slugs when we talked English units in high school physics and while\n",
            "the teacher was an ex-Navy fighter jock the book certainly wasn't\n",
            "produced by the military.\n",
            "\n",
            "[Poundals were just too flinking small and made the math come out\n",
            "funny; sort of the same reason proponents of SI give for using that.] \n",
            "\n",
            "-- \n",
            "\"Insisting on perfect safety is for people who don't have the balls to live\n",
            " in the real world.\"   -- Mary Shafer, NASA Ames Dryden\n"
          ]
        }
      ],
      "source": [
        "print(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating transformers\n",
        "\n",
        "First, we would like a transformer that extracts the subject and\n",
        "body of each post. Since this is a stateless transformation (does not\n",
        "require state information from training data), we can define a function that\n",
        "performs the data transformation then use\n",
        ":class:`~sklearn.preprocessing.FunctionTransformer` to create a scikit-learn\n",
        "transformer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def subject_body_extractor(posts):\n",
        "    # construct object dtype array with two columns\n",
        "    # first column = 'subject' and second column = 'body'\n",
        "    features = np.empty(shape=(len(posts), 2), dtype=object)\n",
        "    for i, text in enumerate(posts):\n",
        "        # temporary variable `_` stores '\\n\\n'\n",
        "        headers, _, body = text.partition(\"\\n\\n\")\n",
        "        # store body text in second column\n",
        "        features[i, 1] = body\n",
        "\n",
        "        prefix = \"Subject:\"\n",
        "        sub = \"\"\n",
        "        # save text after 'Subject:' in first column\n",
        "        for line in headers.split(\"\\n\"):\n",
        "            if line.startswith(prefix):\n",
        "                sub = line[len(prefix) :]\n",
        "                break\n",
        "        features[i, 0] = sub\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "subject_body_transformer = FunctionTransformer(subject_body_extractor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will also create a transformer that extracts the\n",
        "length of the text and the number of sentences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def text_stats(posts):\n",
        "    return [{\"length\": len(text), \"num_sentences\": text.count(\".\")} for text in posts]\n",
        "\n",
        "\n",
        "text_stats_transformer = FunctionTransformer(text_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification pipeline\n",
        "\n",
        "The pipeline below extracts the subject and body from each post using\n",
        "``SubjectBodyExtractor``, producing a (n_samples, 2) array. This array is\n",
        "then used to compute standard bag-of-words features for the subject and body\n",
        "as well as text length and number of sentences on the body, using\n",
        "``ColumnTransformer``. We combine them, with weights, then train a\n",
        "classifier on the combined set of features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(\n",
        "    [\n",
        "        # Extract subject & body\n",
        "        (\"subjectbody\", subject_body_transformer),\n",
        "        # Use ColumnTransformer to combine the subject and body features\n",
        "        (\n",
        "            \"union\",\n",
        "            ColumnTransformer(\n",
        "                [\n",
        "                    # bag-of-words for subject (col 0)\n",
        "                    (\"subject\", TfidfVectorizer(min_df=50), 0),\n",
        "                    # bag-of-words with decomposition for body (col 1)\n",
        "                    (\n",
        "                        \"body_bow\",\n",
        "                        Pipeline(\n",
        "                            [\n",
        "                                (\"tfidf\", TfidfVectorizer()),\n",
        "                                (\"best\", TruncatedSVD(n_components=50)),\n",
        "                            ]\n",
        "                        ),\n",
        "                        1,\n",
        "                    ),\n",
        "                    # Pipeline for pulling text stats from post's body\n",
        "                    (\n",
        "                        \"body_stats\",\n",
        "                        Pipeline(\n",
        "                            [\n",
        "                                (\n",
        "                                    \"stats\",\n",
        "                                    text_stats_transformer,\n",
        "                                ),  # returns a list of dicts\n",
        "                                (\n",
        "                                    \"vect\",\n",
        "                                    DictVectorizer(),\n",
        "                                ),  # list of dicts -> feature matrix\n",
        "                            ]\n",
        "                        ),\n",
        "                        1,\n",
        "                    ),\n",
        "                ],\n",
        "                # weight above ColumnTransformer features\n",
        "                transformer_weights={\n",
        "                    \"subject\": 0.8,\n",
        "                    \"body_bow\": 0.5,\n",
        "                    \"body_stats\": 1.0,\n",
        "                },\n",
        "            ),\n",
        "        ),\n",
        "        # Use a SVC classifier on the combined features\n",
        "        (\"svc\", LinearSVC(dual=False)),\n",
        "    ],\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we fit our pipeline on the training data and use it to predict\n",
        "topics for ``X_test``. Performance metrics of our pipeline are then printed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pipeline] ....... (step 1 of 3) Processing subjectbody, total=   0.0s\n",
            "[Pipeline] ............. (step 2 of 3) Processing union, total=   1.4s\n",
            "[Pipeline] ............... (step 3 of 3) Processing svc, total=   0.0s\n",
            "Classification report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       396\n",
            "           1       0.86      0.83      0.85       394\n",
            "\n",
            "    accuracy                           0.85       790\n",
            "   macro avg       0.85      0.85      0.85       790\n",
            "weighted avg       0.85      0.85      0.85       790\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"Classification report:\\n\\n{}\".format(classification_report(y_test, y_pred)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 ('tft')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "269ffad4faf381fd223c734db5a016eeb9dc0acf3c9e80f7bf1eaf7686d11d5a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
