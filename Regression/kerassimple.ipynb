{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-21T07:24:46.121789Z","iopub.execute_input":"2021-11-21T07:24:46.122273Z","iopub.status.idle":"2021-11-21T07:24:46.143059Z","shell.execute_reply.started":"2021-11-21T07:24:46.122184Z","shell.execute_reply":"2021-11-21T07:24:46.142231Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# -----------------------------------------------------------------\n# Some parameters to config \n\nEPOCHS = 888\nBATCH_SIZE = 2048\nACTIVATION = 'swish'\nLEARNING_RATE = 0.0007\nLABEL_SMOOTHING=1e-3\nFOLDS = 5\nRANDOM_STATE = 42","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:24:46.144572Z","iopub.execute_input":"2021-11-21T07:24:46.144904Z","iopub.status.idle":"2021-11-21T07:24:46.149338Z","shell.execute_reply.started":"2021-11-21T07:24:46.144869Z","shell.execute_reply":"2021-11-21T07:24:46.148365Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv',index_col='id')\ntest_data = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv',index_col='id')\nsample_sub_data = pd.read_csv('../input/tabular-playground-series-nov-2021/sample_submission.csv',index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:24:46.163436Z","iopub.execute_input":"2021-11-21T07:24:46.163714Z","iopub.status.idle":"2021-11-21T07:25:13.565244Z","shell.execute_reply.started":"2021-11-21T07:24:46.163686Z","shell.execute_reply":"2021-11-21T07:25:13.564456Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"target_col = train_data.columns.difference(test_data.columns)[0]\nx_raw = train_data.drop(columns=target_col)\ny_raw = train_data[target_col]\n\nX_test_raw = test_data.iloc[:,:]","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:25:13.566757Z","iopub.execute_input":"2021-11-21T07:25:13.567027Z","iopub.status.idle":"2021-11-21T07:25:13.719600Z","shell.execute_reply.started":"2021-11-21T07:25:13.566992Z","shell.execute_reply":"2021-11-21T07:25:13.718837Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Split Dataset","metadata":{}},{"cell_type":"code","source":"# Check NA\nmissing_val = x_raw.isnull().sum()\nprint(missing_val[missing_val > 0])\n\nfrom sklearn.model_selection import train_test_split \n\n# x, x_val, y, y_val = train_test_split(x, y, train_size = 0.85, random_state = RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:25:13.720863Z","iopub.execute_input":"2021-11-21T07:25:13.721125Z","iopub.status.idle":"2021-11-21T07:25:14.642350Z","shell.execute_reply.started":"2021-11-21T07:25:13.721091Z","shell.execute_reply":"2021-11-21T07:25:14.641649Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Scaler transformer","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\ntransformer_all_cols = make_pipeline(\n    StandardScaler(),\n    MinMaxScaler(feature_range=(0, 1))\n)\n\npreprocessor = make_column_transformer(\n    (transformer_all_cols, x_raw.columns[:]),\n)\n\n# X_tran_train = preprocessor.fit_transform(x_raw)\n# X_valid = preprocessor.transform(X_valid)\n# X_test = preprocessor.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:25:14.645413Z","iopub.execute_input":"2021-11-21T07:25:14.645954Z","iopub.status.idle":"2021-11-21T07:25:14.655916Z","shell.execute_reply.started":"2021-11-21T07:25:14.645914Z","shell.execute_reply":"2021-11-21T07:25:14.655213Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"### standardize data\n# scaler = StandardScaler()\n\n# X_tran_train = pd.DataFrame(columns=x_raw.columns, data=scaler.fit_transform(x_raw))\n# X_test = pd.DataFrame(columns=X_test.columns, data=scaler.transform(X_test))","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:25:14.657614Z","iopub.execute_input":"2021-11-21T07:25:14.657919Z","iopub.status.idle":"2021-11-21T07:25:14.663949Z","shell.execute_reply.started":"2021-11-21T07:25:14.657883Z","shell.execute_reply":"2021-11-21T07:25:14.663251Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ndef load_model():\n    \n    early_stopping = EarlyStopping(\n        patience=20,\n        min_delta=0,\n        monitor='val_loss',\n        restore_best_weights=True,\n        verbose=0,\n        mode='min', \n        baseline=None,\n    )\n    plateau = ReduceLROnPlateau(\n            monitor='val_loss', \n            factor=0.2, \n            patience=7, \n            verbose=0,\n            mode='min')\n\n# -----------------------------------------------------------------\n# Model Conv - DropOut - BatchNorm - Activation - Pool -->\n# , activation=ACTIVATION    layers.Activation(ACTIVATION),\n\n    model = keras.Sequential([\n    layers.BatchNormalization(input_shape = [x_raw.shape[1]], name='input'),\n    layers.Dense(128, activation=ACTIVATION),\n    layers.Dropout(rate = 0.5),\n    layers.BatchNormalization(),\n    layers.Dense(64, activation=ACTIVATION),\n    layers.Dropout(rate = 0.5),\n    layers.BatchNormalization(),\n    layers.Dense(32, activation=ACTIVATION),\n    layers.Dropout(rate = 0.5),\n    layers.BatchNormalization(),\n    layers.Dense(1, activation = 'sigmoid'),\n    ])\n\n# -----------------------------------------------------------------\n\n    model.compile(\n        optimizer= tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING),\n        metrics=['AUC'],\n    )\n    \n    return model, early_stopping, plateau","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:25:14.665544Z","iopub.execute_input":"2021-11-21T07:25:14.665799Z","iopub.status.idle":"2021-11-21T07:25:19.505418Z","shell.execute_reply.started":"2021-11-21T07:25:14.665766Z","shell.execute_reply":"2021-11-21T07:25:19.504676Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Kfold","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n\npreds_valid_f = {}\npreds_test = []\ntotal_auc = []\nf_scores = []\n\nkf = StratifiedKFold(n_splits=FOLDS,random_state=RANDOM_STATE,shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:25:19.507702Z","iopub.execute_input":"2021-11-21T07:25:19.507986Z","iopub.status.idle":"2021-11-21T07:25:19.516501Z","shell.execute_reply.started":"2021-11-21T07:25:19.507940Z","shell.execute_reply":"2021-11-21T07:25:19.515526Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for fold, (train_index, valid_index) in enumerate(kf.split(x_raw, y_raw)):\n\n    X_train, X_valid = x_raw.iloc[train_index], x_raw.iloc[valid_index]\n    y_train, y_valid = y_raw.iloc[train_index], y_raw.iloc[valid_index]\n\n    #   --------------------------------------------------------  \n    # Preprocessing\n    index_valid  = X_valid.index.tolist()\n    \n    X_train = preprocessor.fit_transform(X_train)\n    X_valid = preprocessor.transform(X_valid)\n    X_test = preprocessor.transform(X_test_raw)\n    #  ----------------------------------------------------------    \n    # Model\n    \n    model, early_stopping, plateau  = load_model()\n\n    history = model.fit(  X_train, y_train,\n                validation_data = (X_valid, y_valid),\n                batch_size = BATCH_SIZE, \n                epochs = EPOCHS,\n                callbacks = [early_stopping, plateau],\n                shuffle = True,\n                verbose = 0\n              )\n\n    #  ----------------------------------------------------------\n    #  oof\n    preds_valid = model.predict(X_valid, batch_size=BATCH_SIZE).reshape(1,-1)[0] \n    \n    #  ----------------------------------------------------------\n    #  test  predictions\n    preds_test.append(model.predict(X_test, batch_size=BATCH_SIZE).reshape(1,-1)[0])\n    \n    #  ----------------------------------------------------------\n    #  Saving  scores to plot the end  \n    scores = pd.DataFrame(history.history)\n    scores['folds'] = fold\n    \n    if fold == 0:\n        f_scores = scores \n    else: \n        f_scores = pd.concat([f_scores, scores], axis  = 0)\n        \n    #  ----------------------------------------------------------\n    #  concatenating valid preds\n    preds_valid_f.update(dict(zip(index_valid, preds_valid)))\n\n    # Getting score for a fold model\n    fold_auc = roc_auc_score(y_valid, preds_valid)\n    print(f\"Fold {fold} roc_auc_score: {fold_auc}\")\n\n    # Total auc\n    total_auc.append(fold_auc)\n\nprint(f\"mean roc_auc_score: {np.mean(total_auc)}, std: {np.std(total_auc)}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:27:23.260792Z","iopub.execute_input":"2021-11-21T07:27:23.261165Z","iopub.status.idle":"2021-11-21T07:28:11.500099Z","shell.execute_reply.started":"2021-11-21T07:27:23.261131Z","shell.execute_reply":"2021-11-21T07:28:11.499235Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# AUC","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor fold in range(f_scores['folds'].nunique()):\n    history_f = f_scores[f_scores['folds'] == fold]\n\n    fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(14,4))\n    fig.suptitle('Fold : '+str(fold), fontsize=14)\n        \n    plt.subplot(1,2,1)\n    plt.plot(history_f.loc[:, ['loss', 'val_loss']], label= ['loss', 'val_loss'])\n    plt.legend(fontsize=15)\n    plt.grid()\n    \n    plt.subplot(1,2,2)\n    plt.plot(history_f.loc[:, ['auc', 'val_auc']],label= ['auc', 'val_auc'])\n    plt.legend(fontsize=15)\n    plt.grid()\n    \n    print(\"Validation Loss: {:0.4f}\".format(history_f['val_loss'].min()));","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:28:11.501945Z","iopub.execute_input":"2021-11-21T07:28:11.502393Z","iopub.status.idle":"2021-11-21T07:28:13.688300Z","shell.execute_reply.started":"2021-11-21T07:28:11.502353Z","shell.execute_reply":"2021-11-21T07:28:13.687619Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\")\nsub[target_col] = np.mean(preds_test, axis = 0)\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:28:13.689484Z","iopub.execute_input":"2021-11-21T07:28:13.690119Z","iopub.status.idle":"2021-11-21T07:28:15.186356Z","shell.execute_reply.started":"2021-11-21T07:28:13.690077Z","shell.execute_reply":"2021-11-21T07:28:15.185642Z"},"trusted":true},"execution_count":13,"outputs":[]}]}