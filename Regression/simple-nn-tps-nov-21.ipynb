{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Deep Learning with Feature Engineering \n","\n","This is a simple model with neural networks, I hope that you like it. It will be a pleasure hear any comment or feedback."]},{"cell_type":"markdown","metadata":{},"source":["The reference of this notebook is taken from this link :\n","https://www.kaggle.com/javiervallejos/simple-nn-with-good-results-tps-nov-21"]},{"cell_type":"markdown","metadata":{},"source":["# Upvote If you COPY"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-20T05:29:54.734279Z","iopub.status.busy":"2021-11-20T05:29:54.733582Z","iopub.status.idle":"2021-11-20T05:30:23.482839Z","shell.execute_reply":"2021-11-20T05:30:23.481974Z","shell.execute_reply.started":"2021-11-20T05:29:54.734183Z"},"papermill":{"duration":28.22398,"end_time":"2021-11-10T03:26:44.193802","exception":false,"start_time":"2021-11-10T03:26:15.969822","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","\n","# Reading the dataset\n","raw_train = pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\")\n","raw_test = pd.read_csv(\"../input/tabular-playground-series-nov-2021/test.csv\")\n","\n","train = raw_train.drop(['id','target'], axis = 1)\n","test = raw_test.drop('id', axis = 1)\n","\n","target = raw_train.target\n","id_train = raw_train.id\n","id_test = raw_test.id\n","\n","\n","# -----------------------------------------------------------------\n","# Some parameters to config \n","\n","EPOCHS = 840\n","BATCH_SIZE = 2048 \n","ACTIVATION = 'swish'\n","LEARNING_RATE = 0.000265713\n","FOLDS = 5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Feature Engineering\n","\n","To begin I split the dataset by distribution of each column and added some basic columns (mea, std, var, mean, etc)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-20T05:30:23.484866Z","iopub.status.busy":"2021-11-20T05:30:23.484612Z","iopub.status.idle":"2021-11-20T05:30:36.649722Z","shell.execute_reply":"2021-11-20T05:30:36.648859Z","shell.execute_reply.started":"2021-11-20T05:30:23.484833Z"},"papermill":{"duration":13.455351,"end_time":"2021-11-10T03:26:57.659068","exception":false,"start_time":"2021-11-10T03:26:44.203717","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.pipeline import make_pipeline\n","from sklearn.compose import make_column_transformer\n","\n","# the number 2 is just a threshold to split \n","h_skew = train.loc[:,train.skew() >= 2].columns  # with Skewed \n","l_skew = train.loc[:,train.skew() < 2].columns   # Bimodal\n","\n","# -----------------------------------------------------------------\n","# Skewed distrubutions\n","\n","# train['mean_h'] = train[h_skew].mean(axis=1)\n","# test['mean_h'] = test[h_skew].mean(axis=1)\n","\n","# train['std_h'] = np.log1p(train[h_skew].std(axis=1))\n","# test['std_h'] = np.log1p(test[h_skew].std(axis=1))\n","\n","train['median_h'] = train[h_skew].median(axis=1)\n","test['median_h'] = test[h_skew].median(axis=1)\n","\n","# train['min_h'] = train[h_skew].min(axis=1)\n","# test['min_h'] = test[h_skew].min(axis=1)\n","\n","# train['skew_h'] = train[h_skew].skew(axis=1)\n","# test['skew_h'] = test[h_skew].skew(axis=1)\n","\n","# train['max_h'] = train[h_skew].max(axis=1)\n","# test['max_h'] = test[h_skew].max(axis=1)\n","\n","train['var_h'] = train[h_skew].var(axis=1)\n","test['var_h'] = test[h_skew].var(axis=1)\n","\n","# -----------------------------------------------------------------\n","# Bimodal distributions\n","\n","train['mean_l'] = train[l_skew].mean(axis=1)\n","test['mean_l'] = test[l_skew].mean(axis=1)\n","\n","train['std_l'] = train[l_skew].std(axis=1)\n","test['std_l'] = test[l_skew].std(axis=1)\n","\n","train['median_l'] = train[l_skew].median(axis=1)\n","test['median_l'] = test[l_skew].median(axis=1)\n","\n","# train['min_l'] = train[l_skew].min(axis=1)\n","# test['min_l'] = test[l_skew].min(axis=1)\n","\n","train['skew_l'] = train[l_skew].skew(axis=1)\n","test['skew_l'] = test[l_skew].skew(axis=1)\n","\n","train['max_l'] = train[l_skew].max(axis=1)\n","test['max_l'] = test[l_skew].max(axis=1)\n","\n","train['var_l'] = train[l_skew].var(axis=1)\n","test['var_l'] = test[l_skew].var(axis=1)\n","\n","\n","raw_train = train.copy()\n","raw_test = test.copy()\n","\n","# -----------------------------------------------------------------\n","# Scaling and Nomalization\n","\n","transformer_high_skew = make_pipeline(\n","    StandardScaler(), \n","    MinMaxScaler(feature_range=(0, 1))\n",")\n","\n","transformer_low_skew = make_pipeline(\n","    StandardScaler(),\n","    MinMaxScaler(feature_range=(0, 1))\n",")\n","\n","new_cols = train.columns[-8:]\n","\n","transformer_new_cols = make_pipeline(\n","    StandardScaler(),\n","    MinMaxScaler(feature_range=(0, 1))\n",")\n","\n","preprocessor = make_column_transformer(\n","    (transformer_high_skew, l_skew),\n","    (transformer_low_skew, h_skew),\n","    (transformer_new_cols, new_cols),\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-20T05:30:36.651534Z","iopub.status.busy":"2021-11-20T05:30:36.651241Z","iopub.status.idle":"2021-11-20T05:30:41.565883Z","shell.execute_reply":"2021-11-20T05:30:41.565135Z","shell.execute_reply.started":"2021-11-20T05:30:36.651496Z"},"papermill":{"duration":4.804345,"end_time":"2021-11-10T03:27:02.470705","exception":false,"start_time":"2021-11-10T03:26:57.66636","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import callbacks\n","\n","import tensorflow as tf\n","import random\n","import os\n","\n","# -----------------------------------------------------------------\n","# Seed \n","\n","my_seed = 42\n","def seedAll(seed):\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    \n","seedAll(my_seed)\n","\n","# -----------------------------------------------------------------\n","\n","def load_model(name:str):\n","    \n","    early_stopping = callbacks.EarlyStopping(\n","        patience=20,\n","        min_delta=0,\n","        monitor='val_loss',\n","        restore_best_weights=True,\n","        verbose=0,\n","        mode='min', \n","        baseline=None,\n","    )\n","\n","    plateau = callbacks.ReduceLROnPlateau(\n","            monitor='val_loss', \n","            factor=0.2, \n","            patience=7, \n","            verbose=0,\n","            mode='min')\n","\n","# -----------------------------------------------------------------\n","# Model \n","\n","    model = keras.Sequential([\n","        layers.Dense(108, activation = ACTIVATION, input_shape = [train.shape[1]]),      \n","        layers.Dense(64, activation =ACTIVATION), \n","        layers.Dense(32, activation =ACTIVATION),\n","        layers.Dense(1, activation='sigmoid'),\n","    ])\n","\n","# -----------------------------------------------------------------\n","\n","    model.compile(\n","        optimizer= keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n","        loss='binary_crossentropy',\n","        metrics=['AUC'],\n","    )\n","    \n","    return model, early_stopping, plateau"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-20T05:30:41.568085Z","iopub.status.busy":"2021-11-20T05:30:41.567816Z","iopub.status.idle":"2021-11-20T05:30:41.713217Z","shell.execute_reply":"2021-11-20T05:30:41.712434Z","shell.execute_reply.started":"2021-11-20T05:30:41.568037Z"},"trusted":true},"outputs":[],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-20T05:39:56.57812Z","iopub.status.busy":"2021-11-20T05:39:56.577834Z","iopub.status.idle":"2021-11-20T05:39:56.583808Z","shell.execute_reply":"2021-11-20T05:39:56.582664Z","shell.execute_reply.started":"2021-11-20T05:39:56.578081Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_auc_score, log_loss\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n","\n","preds_valid_f = {}\n","preds_test = []\n","total_auc = []\n","f_scores = []\n","\n","kf = StratifiedKFold(n_splits=FOLDS,random_state=0,shuffle=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-20T05:40:21.455798Z","iopub.status.busy":"2021-11-20T05:40:21.455313Z","iopub.status.idle":"2021-11-20T05:40:21.558728Z","shell.execute_reply":"2021-11-20T05:40:21.557993Z","shell.execute_reply.started":"2021-11-20T05:40:21.45576Z"},"trusted":true},"outputs":[],"source":["for fold,(train_index, valid_index) in enumerate(kf.split(train,target)):\n","    print(train_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-20T05:44:37.469792Z","iopub.status.busy":"2021-11-20T05:44:37.469361Z","iopub.status.idle":"2021-11-20T05:47:06.699399Z","shell.execute_reply":"2021-11-20T05:47:06.698643Z","shell.execute_reply.started":"2021-11-20T05:44:37.469754Z"},"papermill":{"duration":904.734462,"end_time":"2021-11-10T03:42:07.212492","exception":false,"start_time":"2021-11-10T03:27:02.47803","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_auc_score, log_loss\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n","\n","preds_valid_f = {}\n","preds_test = []\n","total_auc = []\n","f_scores = []\n","\n","kf = StratifiedKFold(n_splits=FOLDS,random_state=0,shuffle=True)\n","\n","for fold,(train_index, valid_index) in enumerate(kf.split(train,target)):\n","\n","    X_train,X_valid = train.loc[train_index], train.loc[valid_index]\n","    y_train,y_valid = target.loc[train_index], target.loc[valid_index]\n","\n","    #   --------------------------------------------------------  \n","    # Preprocessing\n","    index_valid  = X_valid.index.tolist()\n","    test  = raw_test.copy()\n","    \n","    X_train = preprocessor.fit_transform(X_train)\n","    X_valid = preprocessor.transform(X_valid)\n","    test = preprocessor.transform(test)\n","    \n","    #  ----------------------------------------------------------    \n","    # Model\n","    \n","    model, early_stopping, plateau  = load_model('version1')\n","\n","    history = model.fit(  X_train, y_train,\n","                validation_data = (X_valid, y_valid),\n","                batch_size = BATCH_SIZE, \n","                epochs = 1,\n","                callbacks = [early_stopping, plateau],\n","                shuffle = True,\n","                verbose = 0\n","              )\n","\n","    #  ----------------------------------------------------------\n","    #  oof\n","    preds_valid = model.predict(X_valid).reshape(1,-1)[0] \n","    \n","    #  ----------------------------------------------------------\n","    #  test  predictions\n","    preds_test.append(model.predict(test).reshape(1,-1)[0])\n","    \n","    #  ----------------------------------------------------------\n","    #  Saving  scores to plot the end  \n","    scores = pd.DataFrame(history.history)\n","    scores['folds'] = fold\n","    \n","    if fold == 0:\n","        f_scores = scores \n","    else: \n","        f_scores = pd.concat([f_scores, scores], axis  = 0)\n","        \n","    #  ----------------------------------------------------------\n","    #  concatenating valid preds\n","    preds_valid_f.update(dict(zip(index_valid, preds_valid)))\n","\n","    # Getting score for a fold model\n","    fold_auc = roc_auc_score(y_valid, preds_valid)\n","    print(f\"Fold {fold} roc_auc_score: {fold_auc}\")\n","\n","    # Total auc\n","    total_auc.append(fold_auc)\n","\n","print(f\"mean roc_auc_score: {np.mean(total_auc)}, std: {np.std(total_auc)}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Outcomes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T23:15:36.244289Z","iopub.status.busy":"2021-11-10T23:15:36.243992Z","iopub.status.idle":"2021-11-10T23:15:38.985284Z","shell.execute_reply":"2021-11-10T23:15:38.984461Z","shell.execute_reply.started":"2021-11-10T23:15:36.24422Z"},"papermill":{"duration":2.963485,"end_time":"2021-11-10T03:42:10.185167","exception":false,"start_time":"2021-11-10T03:42:07.221682","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","for fold in range(f_scores['folds'].nunique()):\n","    history_f = f_scores[f_scores['folds'] == fold]\n","\n","    fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(14,4))\n","    fig.suptitle('Fold : '+str(fold), fontsize=14)\n","        \n","    plt.subplot(1,2,1)\n","    plt.plot(history_f.loc[:, ['loss', 'val_loss']], label= ['loss', 'val_loss'])\n","    plt.legend(fontsize=15)\n","    plt.grid()\n","    \n","    plt.subplot(1,2,2)\n","    plt.plot(history_f.loc[:, ['auc', 'val_auc']],label= ['auc', 'val_auc'])\n","    plt.legend(fontsize=15)\n","    plt.grid()\n","    \n","    print(\"Validation Loss: {:0.4f}\".format(history_f['val_loss'].min()));"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-10T23:15:38.987038Z","iopub.status.busy":"2021-11-10T23:15:38.986776Z","iopub.status.idle":"2021-11-10T23:15:40.50139Z","shell.execute_reply":"2021-11-10T23:15:40.500528Z","shell.execute_reply.started":"2021-11-10T23:15:38.987002Z"},"papermill":{"duration":1.933432,"end_time":"2021-11-10T03:42:12.172879","exception":false,"start_time":"2021-11-10T03:42:10.239447","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["sub = pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\")\n","sub['target'] = np.mean(preds_test, axis = 0)\n","sub.to_csv('submission.csv', index=False)\n","sub.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"vscode":{"interpreter":{"hash":"369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"}}},"nbformat":4,"nbformat_minor":4}
