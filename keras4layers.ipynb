{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-20T13:19:02.221897Z","iopub.execute_input":"2021-11-20T13:19:02.222422Z","iopub.status.idle":"2021-11-20T13:19:02.24862Z","shell.execute_reply.started":"2021-11-20T13:19:02.222306Z","shell.execute_reply":"2021-11-20T13:19:02.247697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------------------------------------------------------\n# Some parameters to config \n\nEPOCHS = 777\nBATCH_SIZE = 1024 \nACTIVATION = 'swish'\nLEARNING_RATE = 1e-4\nLABEL_SMOOTHING=1e-3\nFOLDS = 10\nRANDOM_STATE = 42","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:19:02.249905Z","iopub.execute_input":"2021-11-20T13:19:02.25014Z","iopub.status.idle":"2021-11-20T13:19:02.255104Z","shell.execute_reply.started":"2021-11-20T13:19:02.250112Z","shell.execute_reply":"2021-11-20T13:19:02.254247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv',index_col='id')\ntest_data = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv',index_col='id')\nsample_sub_data = pd.read_csv('../input/tabular-playground-series-nov-2021/sample_submission.csv',index_col='id')","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:19:02.256854Z","iopub.execute_input":"2021-11-20T13:19:02.257335Z","iopub.status.idle":"2021-11-20T13:19:28.30637Z","shell.execute_reply.started":"2021-11-20T13:19:02.257291Z","shell.execute_reply":"2021-11-20T13:19:28.305534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_col = train_data.columns.difference(test_data.columns)[0]\nx_raw = train_data.drop(columns=target_col)\ny_raw = train_data[target_col]\n\nX_test = test_data.iloc[:,:]","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:24:52.583676Z","iopub.execute_input":"2021-11-20T13:24:52.583988Z","iopub.status.idle":"2021-11-20T13:24:52.785347Z","shell.execute_reply.started":"2021-11-20T13:24:52.583952Z","shell.execute_reply":"2021-11-20T13:24:52.784486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split Dataset","metadata":{}},{"cell_type":"code","source":"# Check NA\nmissing_val = x_raw.isnull().sum()\nprint(missing_val[missing_val > 0])\n\nfrom sklearn.model_selection import train_test_split \n\n# x, x_val, y, y_val = train_test_split(x, y, train_size = 0.85, random_state = RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:24:59.059243Z","iopub.execute_input":"2021-11-20T13:24:59.059544Z","iopub.status.idle":"2021-11-20T13:25:00.039756Z","shell.execute_reply.started":"2021-11-20T13:24:59.05951Z","shell.execute_reply":"2021-11-20T13:25:00.038804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaler transformer","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\ntransformer_all_cols = make_pipeline(\n    StandardScaler(),\n    MinMaxScaler(feature_range=(0, 1))\n)\n\npreprocessor = make_column_transformer(\n    (transformer_all_cols, x_raw.columns[:]),\n)\n\n# X_tran_train = preprocessor.fit_transform(x_raw)\n# X_valid = preprocessor.transform(X_valid)\n# test = preprocessor.transform(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:25:01.474749Z","iopub.execute_input":"2021-11-20T13:25:01.475369Z","iopub.status.idle":"2021-11-20T13:25:01.488133Z","shell.execute_reply.started":"2021-11-20T13:25:01.47533Z","shell.execute_reply":"2021-11-20T13:25:01.487297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### standardize data\nscaler = StandardScaler()\n\nX_tran_train = pd.DataFrame(columns=x_raw.columns, data=scaler.fit_transform(x_raw))\nX_test = pd.DataFrame(columns=X_test.columns, data=scaler.transform(X_test))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:25:04.282872Z","iopub.execute_input":"2021-11-20T13:25:04.283136Z","iopub.status.idle":"2021-11-20T13:25:05.931773Z","shell.execute_reply.started":"2021-11-20T13:25:04.283108Z","shell.execute_reply":"2021-11-20T13:25:05.930827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ndef load_model():\n    \n    early_stopping = EarlyStopping(\n        patience=16,\n        min_delta=0,\n        monitor='val_loss',\n        restore_best_weights=True,\n        verbose=0,\n        mode='min', \n        baseline=None,\n    )\n    plateau = ReduceLROnPlateau(\n            monitor='val_loss', \n            factor=0.2, \n            patience=5, \n            verbose=0,\n            mode='min')\n\n# -----------------------------------------------------------------\n# Model \n\n    model = keras.Sequential([\n    layers.BatchNormalization(),\n    layers.Dense(128, activation=ACTIVATION, input_shape = [x_raw.shape[1]], name='input'),\n    layers.Dropout(rate = 0.25),\n    layers.BatchNormalization(),\n    layers.Dense(64, activation=ACTIVATION),\n    layers.Dropout(rate = 0.25),\n    layers.BatchNormalization(),\n    layers.Dense(32, activation=ACTIVATION), \n    layers.Dropout(rate = 0.25),\n    layers.Dense(1, activation = 'sigmoid'),\n    ])\n\n# -----------------------------------------------------------------\n\n    model.compile(\n        optimizer= tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=LABEL_SMOOTHING),\n        metrics=['AUC'],\n    )\n    \n    return model, early_stopping, plateau","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:25:07.182405Z","iopub.execute_input":"2021-11-20T13:25:07.183304Z","iopub.status.idle":"2021-11-20T13:25:12.440597Z","shell.execute_reply.started":"2021-11-20T13:25:07.183254Z","shell.execute_reply":"2021-11-20T13:25:12.439816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Kfold","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n\npreds_valid_f = {}\npreds_test = []\ntotal_auc = []\nf_scores = []\n\nkf = StratifiedKFold(n_splits=FOLDS,random_state=RANDOM_STATE,shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:25:12.441998Z","iopub.execute_input":"2021-11-20T13:25:12.442689Z","iopub.status.idle":"2021-11-20T13:25:12.448357Z","shell.execute_reply.started":"2021-11-20T13:25:12.442646Z","shell.execute_reply":"2021-11-20T13:25:12.44749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold, (train_index, valid_index) in enumerate(kf.split(X_tran_train, y_raw)):\n\n    X_train, X_valid = X_tran_train.iloc[train_index], X_tran_train.iloc[valid_index]\n    y_train, y_valid = y_raw.iloc[train_index], y_raw.iloc[valid_index]\n\n    #   --------------------------------------------------------  \n    # Preprocessing\n    index_valid  = X_valid.index.tolist()\n#     test  = test.copy()\n    \n    #  ----------------------------------------------------------    \n    # Model\n    \n    model, early_stopping, plateau  = load_model()\n\n    history = model.fit(  X_train, y_train,\n                validation_data = (X_valid, y_valid),\n                batch_size = BATCH_SIZE, \n                epochs = EPOCHS,\n                callbacks = [early_stopping, plateau],\n                shuffle = True,\n                verbose = 0\n              )\n\n    #  ----------------------------------------------------------\n    #  oof\n    preds_valid = model.predict(X_valid, batch_size=BATCH_SIZE).reshape(1,-1)[0] \n    \n    #  ----------------------------------------------------------\n    #  test  predictions\n    preds_test.append(model.predict(X_test, batch_size=BATCH_SIZE).reshape(1,-1)[0])\n    \n    #  ----------------------------------------------------------\n    #  Saving  scores to plot the end  \n    scores = pd.DataFrame(history.history)\n    scores['folds'] = fold\n    \n    if fold == 0:\n        f_scores = scores \n    else: \n        f_scores = pd.concat([f_scores, scores], axis  = 0)\n        \n    #  ----------------------------------------------------------\n    #  concatenating valid preds\n    preds_valid_f.update(dict(zip(index_valid, preds_valid)))\n\n    # Getting score for a fold model\n    fold_auc = roc_auc_score(y_valid, preds_valid)\n    print(f\"Fold {fold} roc_auc_score: {fold_auc}\")\n\n    # Total auc\n    total_auc.append(fold_auc)\n\nprint(f\"mean roc_auc_score: {np.mean(total_auc)}, std: {np.std(total_auc)}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:25:12.681041Z","iopub.execute_input":"2021-11-20T13:25:12.681945Z","iopub.status.idle":"2021-11-20T13:26:16.994661Z","shell.execute_reply.started":"2021-11-20T13:25:12.681904Z","shell.execute_reply":"2021-11-20T13:26:16.993588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AUC","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor fold in range(f_scores['folds'].nunique()):\n    history_f = f_scores[f_scores['folds'] == fold]\n\n    fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(14,4))\n    fig.suptitle('Fold : '+str(fold), fontsize=14)\n        \n    plt.subplot(1,2,1)\n    plt.plot(history_f.loc[:, ['loss', 'val_loss']], label= ['loss', 'val_loss'])\n    plt.legend(fontsize=15)\n    plt.grid()\n    \n    plt.subplot(1,2,2)\n    plt.plot(history_f.loc[:, ['auc', 'val_auc']],label= ['auc', 'val_auc'])\n    plt.legend(fontsize=15)\n    plt.grid()\n    \n    print(\"Validation Loss: {:0.4f}\".format(history_f['val_loss'].min()));","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:26:16.99644Z","iopub.execute_input":"2021-11-20T13:26:16.996774Z","iopub.status.idle":"2021-11-20T13:26:19.352464Z","shell.execute_reply.started":"2021-11-20T13:26:16.996733Z","shell.execute_reply":"2021-11-20T13:26:19.351543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\")\nsub[target_col] = np.mean(preds_test, axis = 0)\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:26:19.35436Z","iopub.execute_input":"2021-11-20T13:26:19.354696Z","iopub.status.idle":"2021-11-20T13:26:20.443056Z","shell.execute_reply.started":"2021-11-20T13:26:19.354655Z","shell.execute_reply":"2021-11-20T13:26:20.442149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub['target'] = np.mean(preds_test, axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:19:28.400591Z","iopub.status.idle":"2021-11-20T13:19:28.400868Z","shell.execute_reply.started":"2021-11-20T13:19:28.400722Z","shell.execute_reply":"2021-11-20T13:19:28.400736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:19:28.401547Z","iopub.status.idle":"2021-11-20T13:19:28.401811Z","shell.execute_reply.started":"2021-11-20T13:19:28.401673Z","shell.execute_reply":"2021-11-20T13:19:28.401687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}