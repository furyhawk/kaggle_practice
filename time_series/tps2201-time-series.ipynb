{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Welcome and have fun learning\n\n#### Linear regression excels at extrapolating trends, but can't learn interactions. XGBoost excels at learning interactions, but can't extrapolate trends. In this lesson, we'll learn how to create \"hybrid\" forecasters that combine complementary learning algorithms and let the strengths of one make up for the weakness of the other. \n\nObjective of this notebook used to be a ~simple~ and robust time series regression for future use.\n\n<blockquote style=\"margin-right:auto; margin-left:auto; padding: 1em; margin:24px;\">\n    <strong>Fork This Notebook!</strong><br>\nCreate your own editable copy of this notebook by clicking on the <strong>Copy and Edit</strong> button in the top right corner.\n</blockquote>\n\n**Notes:**\n\n## Imports and Configuration ##","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nfrom scipy import stats\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\nimport seaborn as sns\n\n\nimport ipywidgets as widgets\nfrom learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import (create_multistep_example,\n                                          load_multistep_data,\n                                          make_lags,\n                                          make_multistep_target,\n                                          plot_multistep)\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom xgboost import XGBRegressor\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport gc\nimport os\nimport math\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-05T03:36:02.403875Z","iopub.execute_input":"2022-01-05T03:36:02.404542Z","iopub.status.idle":"2022-01-05T03:36:04.008930Z","shell.execute_reply.started":"2022-01-05T03:36:02.404401Z","shell.execute_reply":"2022-01-05T03:36:04.006146Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Fine tuning","metadata":{}},{"cell_type":"code","source":"# -----------------------------------------------------------------\n# Some parameters to config \nPRODUCTION = False # True: For submission run. False: Fast trial run\n\n# Hyperparameters\nFOLDS = 20 if PRODUCTION else 5   # Only 5 or 10.\nEPOCHS = 68        # Does not matter with Early stopping. Deep network should not take too much epochs to learn\nBATCH_SIZE = 2048   # large enough to fit RAM. If unstable, tuned downward. 4096 2048\nACTIVATION = 'swish' # swish mish relu selu ;swish overfit more cause of narrow global minimun\nKERNEL_INIT = \"glorot_normal\" # Minimal impact, but give your init the right foot forward glorot_uniform lecun_normal\nLEARNING_RATE = 0.000965713 # Not used. Optimal lr is about half the maximum lr \nLR_FACTOR = 0.5   # LEARNING_RATE * LR_FACTOR = New Learning rate on ReduceLROnPlateau. lower down when the LR oscillate\nMIN_DELTA = 0.0000001 # Default 0.0001 0.0000001\nRLRP_PATIENCE = 5 # Learning Rate reduction on ReduceLROnPlateau\nES_PATIENCE = 16  # Early stopping\nDROPOUT = 0.05     # Act like L1 L2 regulator. lower your learning rate in order to overcome the \"boost\" that the dropout probability gives to the learning rate.\nHIDDEN_LAYERS = [320, 288, 64, 32]\n\nOPTIMIZER = 'adam' # adam adamax nadam\nLOSS ='sparse_categorical_crossentropy' # sparse_categorical_crossentropy does not require onehot encoding on labels. categorical_crossentropy\nMETRICS ='accuracy'  # acc accuracy categorical_accuracy sparse_categorical_accuracy\nACC_VAL_METRICS = 'val_accuracy' # 'val_acc' val_accuracy val_sparse_categorical_accuracy\nACC_METRICS = 'accuracy' # acc accuracy 'sparse_categorical_accuracy'\n\n# The dataset is too huge for trial. Sampling it for speed run!\nSAMPLE = 2262087 if PRODUCTION else 11426   # True for FULL run. Max Sample size per category. For quick test: y counts [1468136, 2262087, 195712, 377, 1, 11426, 62261]  # 4000000 total rows\nVALIDATION_SPLIT = 0.15 # Only used to min dataset for quick test\nMAX_TRIAL = 3           # speed trial any% Not used here\nMI_THRESHOLD = 0.001    # Mutual Information threshold value to drop.\n\nRANDOM_STATE = 42\nVERBOSE = 0\n\n# Admin\nID = \"row_id\"            # Id id x X index\nINPUT = \"../input/tabular-playground-series-jan-2022\"\nTPU = False           # True: use TPU.\nBEST_OR_FOLD = False # True: use Best model, False: use KFOLD softvote\nFEATURE_ENGINEERING = True\nPSEUDO_LABEL = True\nBLEND = True\n\n# time series data common new feature  \nDATE = \"date\"\n\nYEAR = \"year\"\nMONTH = \"month\"\nDAY = \"day\"\n\nDAYOFYEAR = \"dayofyear\"\nDAYOFMONTH = \"dayofMonth\"\nDAYOFWEEK = \"dayofweek\"\nWEEKDAY = \"weekday\"\n\nassert BATCH_SIZE % 2 == 0, \\\n    \"BATCH_SIZE must be even number.\"","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.013085Z","iopub.execute_input":"2022-01-05T03:36:04.013366Z","iopub.status.idle":"2022-01-05T03:36:04.025447Z","shell.execute_reply.started":"2022-01-05T03:36:04.013329Z","shell.execute_reply":"2022-01-05T03:36:04.024426Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36414\ndef smape(y_true, y_pred):\n    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return 100*np.mean(diff)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.027043Z","iopub.execute_input":"2022-01-05T03:36:04.027531Z","iopub.status.idle":"2022-01-05T03:36:04.043261Z","shell.execute_reply.started":"2022-01-05T03:36:04.027497Z","shell.execute_reply":"2022-01-05T03:36:04.042534Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing ##\n\nBefore we can do any feature engineering, we need to *preprocess* the data to get it in a form suitable for analysis. We'll need to:\n- **Load** the data from CSV files\n- **Clean** the data to fix any errors or inconsistencies\n- **Encode** the statistical data type (numeric, categorical)\n- **Impute** any missing values\n\nWe'll wrap all these steps up in a function, which will make easy for you to get a fresh dataframe whenever you need. After reading the CSV file, we'll apply three preprocessing steps, `clean`, `encode`, and `impute`, and then create the data splits: one (`df_train`) for training the model, and one (`df_test`) for making the predictions that you'll submit to the competition for scoring on the leaderboard.","metadata":{}},{"cell_type":"markdown","source":"### Handle Missing Values ###\n\nHandling missing values now will make the feature engineering go more smoothly. We'll impute `0` for missing numeric values and `\"None\"` for missing categorical values. You might like to experiment with other imputation strategies. In particular, you could try creating \"missing value\" indicators: `1` whenever a value was imputed and `0` otherwise.","metadata":{}},{"cell_type":"code","source":"def impute(df):\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.047256Z","iopub.execute_input":"2022-01-05T03:36:04.048061Z","iopub.status.idle":"2022-01-05T03:36:04.056324Z","shell.execute_reply.started":"2022-01-05T03:36:04.047992Z","shell.execute_reply":"2022-01-05T03:36:04.055128Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Reduce Memory usage","metadata":{}},{"cell_type":"code","source":"# for col in df.select_dtypes('int').columns:\n#     df[col] = pd.to_numeric(df[col], downcast = 'integer')\n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.057831Z","iopub.execute_input":"2022-01-05T03:36:04.058598Z","iopub.status.idle":"2022-01-05T03:36:04.073192Z","shell.execute_reply.started":"2022-01-05T03:36:04.058522Z","shell.execute_reply":"2022-01-05T03:36:04.072145Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Data/Feature Engineering","metadata":{}},{"cell_type":"code","source":"def get_basic_ts_features(df):\n    df[YEAR] = df[DATE].dt.year\n    df[MONTH] = df[DATE].dt.month\n    df[DAY] = df[DATE].dt.day\n\n    df[DAYOFYEAR] = df[DATE].dt.dayofyear\n    df[DAYOFMONTH] = df[DATE].dt.days_in_month\n    df[DAYOFWEEK] = df[DATE].dt.dayofweek\n    df[WEEKDAY] = df[DATE].dt.weekday\n    \n#     df.drop(columns=[DATE], inplace = True)\n    \n    return df  ","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.075444Z","iopub.execute_input":"2022-01-05T03:36:04.076188Z","iopub.status.idle":"2022-01-05T03:36:04.090354Z","shell.execute_reply.started":"2022-01-05T03:36:04.076140Z","shell.execute_reply":"2022-01-05T03:36:04.089553Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def feature_engineer(df):\n#     df = get_basic_ts_features(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.091425Z","iopub.execute_input":"2022-01-05T03:36:04.092465Z","iopub.status.idle":"2022-01-05T03:36:04.101919Z","shell.execute_reply.started":"2022-01-05T03:36:04.092415Z","shell.execute_reply":"2022-01-05T03:36:04.101012Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"from pathlib import Path\n\n\ndef load_data():\n    # Read data\n    data_dir = Path(INPUT)\n    df_train = pd.read_csv(data_dir / \"train.csv\", index_col=ID)\n    df_test = pd.read_csv(data_dir / \"test.csv\", index_col=ID)\n    column_y = df_train.columns.difference(\n        df_test.columns)[0]  # column_y target_col label_col\n    return df_train, df_test, column_y","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\n\n\ndef load_data():\n    # Read data\n    data_dir = Path(INPUT)\n    df_train = pd.read_csv(data_dir / \"train.csv\", parse_dates=[DATE],\n                    usecols=['date', 'country', 'store', 'product', 'num_sold'],\n                    dtype={\n                        'country': 'category',\n                        'store': 'category',\n                        'product': 'category',\n                        'num_sold': 'float32',\n                    },\n                    infer_datetime_format=True,)\n    df_test = pd.read_csv(data_dir / \"test.csv\", index_col=ID, parse_dates=[DATE])\n    column_y = df_train.columns.difference(\n        df_test.columns)[0]  # column_y target_col label_col\n    df_train[DATE] = pd.to_datetime(df_train[DATE])\n    df_test[DATE] = pd.to_datetime(df_test[DATE])\n    return df_train, df_test, column_y\n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.103200Z","iopub.execute_input":"2022-01-05T03:36:04.104965Z","iopub.status.idle":"2022-01-05T03:36:04.115740Z","shell.execute_reply.started":"2022-01-05T03:36:04.104914Z","shell.execute_reply":"2022-01-05T03:36:04.114729Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def process_data(df_train, df_test):\n    # Preprocessing\n#     df_train = impute(df_train)\n#     df_test = impute(df_test)\n    \n    if FEATURE_ENGINEERING:\n        df_train = feature_engineer(df_train)\n        df_test = feature_engineer(df_test)\n    \n#     df_train = reduce_mem_usage(df_train)\n#     df_test = reduce_mem_usage(df_test)\n\n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.117574Z","iopub.execute_input":"2022-01-05T03:36:04.118018Z","iopub.status.idle":"2022-01-05T03:36:04.132302Z","shell.execute_reply.started":"2022-01-05T03:36:04.117978Z","shell.execute_reply":"2022-01-05T03:36:04.131256Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Load Data #\n\nAnd now we can call the data loader and get the processed data splits:","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_df, test_df, column_y = load_data()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.136264Z","iopub.execute_input":"2022-01-05T03:36:04.136728Z","iopub.status.idle":"2022-01-05T03:36:04.282374Z","shell.execute_reply.started":"2022-01-05T03:36:04.136683Z","shell.execute_reply":"2022-01-05T03:36:04.281426Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Pseudolabeling","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_df, test_df = process_data(train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.290756Z","iopub.execute_input":"2022-01-05T03:36:04.291094Z","iopub.status.idle":"2022-01-05T03:36:04.302189Z","shell.execute_reply.started":"2022-01-05T03:36:04.291049Z","shell.execute_reply":"2022-01-05T03:36:04.301222Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.303741Z","iopub.execute_input":"2022-01-05T03:36:04.304049Z","iopub.status.idle":"2022-01-05T03:36:04.340079Z","shell.execute_reply.started":"2022-01-05T03:36:04.304006Z","shell.execute_reply":"2022-01-05T03:36:04.339365Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data = train_df.copy()\ntrain_data['date'] = train_df.date.dt.to_period('D')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:37:09.961710Z","iopub.execute_input":"2022-01-05T03:37:09.962782Z","iopub.status.idle":"2022-01-05T03:37:09.975870Z","shell.execute_reply.started":"2022-01-05T03:37:09.962722Z","shell.execute_reply":"2022-01-05T03:37:09.975100Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X = train_data.set_index(['date']).sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:37:13.190239Z","iopub.execute_input":"2022-01-05T03:37:13.190740Z","iopub.status.idle":"2022-01-05T03:37:13.196286Z","shell.execute_reply.started":"2022-01-05T03:37:13.190702Z","shell.execute_reply":"2022-01-05T03:37:13.195625Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X.loc[:\"2015-12-31\"]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:38:48.045400Z","iopub.execute_input":"2022-01-05T03:38:48.046169Z","iopub.status.idle":"2022-01-05T03:38:48.066387Z","shell.execute_reply.started":"2022-01-05T03:38:48.046121Z","shell.execute_reply":"2022-01-05T03:38:48.065823Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"X['country']","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:37:29.081078Z","iopub.execute_input":"2022-01-05T03:37:29.081372Z","iopub.status.idle":"2022-01-05T03:37:29.090821Z","shell.execute_reply.started":"2022-01-05T03:37:29.081342Z","shell.execute_reply":"2022-01-05T03:37:29.089885Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:40:07.589903Z","iopub.execute_input":"2022-01-05T03:40:07.590584Z","iopub.status.idle":"2022-01-05T03:40:07.598992Z","shell.execute_reply.started":"2022-01-05T03:40:07.590519Z","shell.execute_reply":"2022-01-05T03:40:07.598286Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"X = MultiColumnLabelEncoder(columns = ['country','store', 'product']).fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:40:16.581784Z","iopub.execute_input":"2022-01-05T03:40:16.582601Z","iopub.status.idle":"2022-01-05T03:40:16.617516Z","shell.execute_reply.started":"2022-01-05T03:40:16.582542Z","shell.execute_reply":"2022-01-05T03:40:16.616598Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"X.loc[:\"2015-12-31\"]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:40:54.989681Z","iopub.execute_input":"2022-01-05T03:40:54.989978Z","iopub.status.idle":"2022-01-05T03:40:55.006767Z","shell.execute_reply.started":"2022-01-05T03:40:54.989946Z","shell.execute_reply":"2022-01-05T03:40:55.005515Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.set_index(['date', 'country', 'store', 'product']).sort_index()\nkaggle_sales = (\n    train_data\n    .groupby(['country', 'store', 'product', 'date'])\n    .mean()\n    .unstack(['country', 'store', 'product'])\n    .loc['2015']\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:40:21.106908Z","iopub.execute_input":"2022-01-05T03:40:21.107247Z","iopub.status.idle":"2022-01-05T03:40:21.164479Z","shell.execute_reply.started":"2022-01-05T03:40:21.107204Z","shell.execute_reply":"2022-01-05T03:40:21.163604Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_data.tail(20)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:43:09.667544Z","iopub.execute_input":"2022-01-05T03:43:09.667878Z","iopub.status.idle":"2022-01-05T03:43:09.685637Z","shell.execute_reply.started":"2022-01-05T03:43:09.667845Z","shell.execute_reply":"2022-01-05T03:43:09.684604Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"kaggle_sales_2016 = (\n    train_data\n    .groupby(['country', 'store', 'product', 'date'])\n    .mean()\n    .unstack(['country', 'store', 'product'])\n    .loc['2016']\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:40:39.341953Z","iopub.execute_input":"2022-01-05T03:40:39.342259Z","iopub.status.idle":"2022-01-05T03:40:39.373782Z","shell.execute_reply.started":"2022-01-05T03:40:39.342225Z","shell.execute_reply":"2022-01-05T03:40:39.372742Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"kaggle_sales_2017 = (\n    train_data\n    .groupby(['country', 'store', 'product', 'date'])\n    .mean()\n    .unstack(['country', 'store', 'product'])\n    .loc['2017']\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:40:41.017484Z","iopub.execute_input":"2022-01-05T03:40:41.018504Z","iopub.status.idle":"2022-01-05T03:40:41.050170Z","shell.execute_reply.started":"2022-01-05T03:40:41.018448Z","shell.execute_reply":"2022-01-05T03:40:41.049223Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# X = train_data.drop(columns=column_y)\n# y = train_data[[column_y]].astype(int)\n\n# X_test = test_data.loc[:,X.columns]\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.490138Z","iopub.status.idle":"2022-01-05T03:36:04.490864Z","shell.execute_reply.started":"2022-01-05T03:36:04.490630Z","shell.execute_reply":"2022-01-05T03:36:04.490661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_sales","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:44:11.134368Z","iopub.execute_input":"2022-01-05T03:44:11.134671Z","iopub.status.idle":"2022-01-05T03:44:11.191183Z","shell.execute_reply.started":"2022-01-05T03:44:11.134639Z","shell.execute_reply":"2022-01-05T03:44:11.190520Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Check NA\nmissing_val = X.isnull().sum()\nprint(missing_val[missing_val > 0])","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:44:14.100526Z","iopub.execute_input":"2022-01-05T03:44:14.101224Z","iopub.status.idle":"2022-01-05T03:44:14.112067Z","shell.execute_reply.started":"2022-01-05T03:44:14.101163Z","shell.execute_reply":"2022-01-05T03:44:14.111076Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_data.groupby(column_y).apply(lambda s: s.sample(min(len(s), 5)))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:44:16.321809Z","iopub.execute_input":"2022-01-05T03:44:16.322370Z","iopub.status.idle":"2022-01-05T03:44:17.565661Z","shell.execute_reply.started":"2022-01-05T03:44:16.322329Z","shell.execute_reply":"2022-01-05T03:44:17.565037Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# y = train_data.loc[:, column_y]\n\n# # YOUR CODE HERE: Make 4 lag features\n# X = make_lags(y, lags=4).dropna()\n\n# # YOUR CODE HERE: Make multistep target\n# y = make_multistep_target(y, steps=16).dropna()\n\n# y, X = y.align(X, join='inner', axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.499375Z","iopub.status.idle":"2022-01-05T03:36:04.499706Z","shell.execute_reply.started":"2022-01-05T03:36:04.499514Z","shell.execute_reply":"2022-01-05T03:36:04.499529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig_dims = (20,10)\nax = kaggle_sales.num_sold.plot(title='Sales Trends', figsize=fig_dims)\n_ = ax.set(ylabel=\"Numbers sold\")","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:44:21.115344Z","iopub.execute_input":"2022-01-05T03:44:21.115849Z","iopub.status.idle":"2022-01-05T03:44:22.572388Z","shell.execute_reply.started":"2022-01-05T03:44:21.115799Z","shell.execute_reply":"2022-01-05T03:44:22.571644Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def show_me(data) :\n    fig_dims = (20,10)\n    fig, ax = plt.subplots(figsize=fig_dims)\n    sns.set_theme(style=\"whitegrid\")\n    dates = pd.date_range(\"1 1 2015\", periods=365, freq=\"D\")\n    dates = pd.date_range(start='1/1/2015', end='31/12/2015',  freq=\"D\")\n    data.index = dates\n    sns.lineplot(data=data, palette=\"tab10\", linewidth=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:44:23.300758Z","iopub.execute_input":"2022-01-05T03:44:23.301542Z","iopub.status.idle":"2022-01-05T03:44:23.307156Z","shell.execute_reply.started":"2022-01-05T03:44:23.301497Z","shell.execute_reply":"2022-01-05T03:44:23.306128Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"Rama_swe = [col for col in kaggle_sales.columns if ('KaggleRama' in col) & ('Sweden' in col)]\nshow_me(kaggle_sales[Rama_swe])","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:44:26.824597Z","iopub.execute_input":"2022-01-05T03:44:26.824896Z","iopub.status.idle":"2022-01-05T03:44:37.561488Z","shell.execute_reply.started":"2022-01-05T03:44:26.824866Z","shell.execute_reply":"2022-01-05T03:44:37.560629Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"kaggle_sales[Rama_swe]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:44:37.563536Z","iopub.execute_input":"2022-01-05T03:44:37.564405Z","iopub.status.idle":"2022-01-05T03:44:37.597514Z","shell.execute_reply.started":"2022-01-05T03:44:37.564356Z","shell.execute_reply":"2022-01-05T03:44:37.596597Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Components and Residuals #\n\nSo that we can design effective hybrids, we need a better understanding of how time series are constructed. We've studied up to now three patterns of dependence: trend, seasons, and cycles. Many time series can be closely described by an additive model of just these three components plus some essentially unpredictable, entirely random *error*:\n\n```\nseries = trend + seasons + cycles + error\n```\n\nEach of the terms in this model we would then call a **component** of the time series.\n\nThe **residuals** of a model are the difference between the target the model was trained on and the predictions the model makes -- the difference between the actual curve and the fitted curve, in other words. Plot the residuals against a feature, and you get the \"left over\" part of the target, or what the model failed to learn about the target from that feature.","metadata":{}},{"cell_type":"code","source":"# You'll add fit and predict methods to this minimal class\nclass BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None  # store column names from fit method\n    def fit(self, X_1, X_2, y):\n        # Train model_1\n        self.model_1.fit(X_1, y)\n\n        # Make predictions\n        y_fit = pd.DataFrame(\n            self.model_1.predict(X_1), \n            index=X_1.index, columns=y.columns,\n        )\n\n        # Compute residuals\n        y_resid = y - y_fit\n        y_resid = y_resid.unstack() # wide to long\n        display(y_resid)\n\n        # Train model_2 on residuals\n        self.model_2.fit(X_2, y_resid)\n\n        # Save column names for predict method\n        self.y_columns = y.columns\n        # Save data for question checking\n        self.y_fit = y_fit\n        self.y_resid = y_resid\n    def predict(self, X_1, X_2):\n        # Predict with model_1\n        y_pred = pd.DataFrame(\n            self.model_1.predict(X_1), \n            index=X_1.index, columns=self.y_columns,\n        )\n        y_pred = y_pred.unstack()  # wide to long\n\n        # Add model_2 predictions to model_1 predictions\n        y_pred += self.model_2.predict(X_2)\n\n        return y_pred.unstack()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:30:32.772825Z","iopub.execute_input":"2022-01-05T04:30:32.773116Z","iopub.status.idle":"2022-01-05T04:30:32.783742Z","shell.execute_reply.started":"2022-01-05T04:30:32.773087Z","shell.execute_reply":"2022-01-05T04:30:32.782667Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"GROUP_INDEX = ['country', 'store', 'product']\n\n# Target series\ny = kaggle_sales.loc[:, column_y]\n\n# X_1: Features for Linear Regression\ndp = DeterministicProcess(index=y.index, order=1)\nX_1 = dp.in_sample()\n\n\n# X_2: Features for XGBoost\nX_2 = X.loc[:\"2015-12-31\"].drop(column_y, axis=1)\n\n# Label encoding for 'family'\n# le = LabelEncoder()  # from sklearn.preprocessing\n# X_2 = X_2.reset_index('date')\n# X_2['date'] = le.fit_transform(X_2['date'])\n\n# Label encoding for seasonality\nX_2[\"day\"] = X_2.index.dayofyear  # values are day of the month\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:29:37.205668Z","iopub.execute_input":"2022-01-05T04:29:37.205988Z","iopub.status.idle":"2022-01-05T04:29:37.221484Z","shell.execute_reply.started":"2022-01-05T04:29:37.205955Z","shell.execute_reply":"2022-01-05T04:29:37.220818Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"X_1","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:51:26.581063Z","iopub.execute_input":"2022-01-05T03:51:26.581524Z","iopub.status.idle":"2022-01-05T03:51:26.593376Z","shell.execute_reply.started":"2022-01-05T03:51:26.581492Z","shell.execute_reply":"2022-01-05T03:51:26.592731Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"X_2.index.dayofyear","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:50:38.177115Z","iopub.execute_input":"2022-01-05T03:50:38.177409Z","iopub.status.idle":"2022-01-05T03:50:38.185177Z","shell.execute_reply.started":"2022-01-05T03:50:38.177379Z","shell.execute_reply":"2022-01-05T03:50:38.184602Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"X_2","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:51:29.891002Z","iopub.execute_input":"2022-01-05T03:51:29.891510Z","iopub.status.idle":"2022-01-05T03:51:29.904360Z","shell.execute_reply.started":"2022-01-05T03:51:29.891457Z","shell.execute_reply":"2022-01-05T03:51:29.903699Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# Model 1 (trend)\nfrom pyearth import Earth\nfrom sklearn.linear_model import ElasticNet, Lasso, Ridge\n\n# Model 2\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n# Boosted Hybrid\n\n# YOUR CODE HERE: Try different combinations of the algorithms above\nmodel = BoostedHybrid(\n    model_1=Ridge(),\n    model_2=KNeighborsRegressor(),\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:30:36.522329Z","iopub.execute_input":"2022-01-05T04:30:36.522634Z","iopub.status.idle":"2022-01-05T04:30:36.528980Z","shell.execute_reply.started":"2022-01-05T04:30:36.522602Z","shell.execute_reply":"2022-01-05T04:30:36.528040Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"y_train, y_valid = y[:\"2015-07-01\"], y[\"2015-07-02\":]\nX1_train, X1_valid = X_1[: \"2015-07-01\"], X_1[\"2015-07-02\" :]\nX2_train, X2_valid = X_2.loc[:\"2015-07-01\"], X_2.loc[\"2015-07-02\":]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:29:45.132297Z","iopub.execute_input":"2022-01-05T04:29:45.132593Z","iopub.status.idle":"2022-01-05T04:29:45.141168Z","shell.execute_reply.started":"2022-01-05T04:29:45.132552Z","shell.execute_reply":"2022-01-05T04:29:45.140536Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:01:21.134755Z","iopub.execute_input":"2022-01-05T04:01:21.135114Z","iopub.status.idle":"2022-01-05T04:01:21.196365Z","shell.execute_reply.started":"2022-01-05T04:01:21.135076Z","shell.execute_reply":"2022-01-05T04:01:21.195628Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"X1_train","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:01:45.585876Z","iopub.execute_input":"2022-01-05T04:01:45.586995Z","iopub.status.idle":"2022-01-05T04:01:45.600365Z","shell.execute_reply.started":"2022-01-05T04:01:45.586948Z","shell.execute_reply":"2022-01-05T04:01:45.599354Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"X2_train","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:01:48.212067Z","iopub.execute_input":"2022-01-05T04:01:48.212393Z","iopub.status.idle":"2022-01-05T04:01:48.228521Z","shell.execute_reply.started":"2022-01-05T04:01:48.212361Z","shell.execute_reply":"2022-01-05T04:01:48.227473Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# Some of the algorithms above do best with certain kinds of\n# preprocessing on the features (like standardization), but this is\n# just a demo.\nmodel.fit(X1_train, X2_train, y_train)\ny_fit = model.predict(X1_train, X2_train).clip(0.0)\ny_pred = model.predict(X1_valid, X2_valid).clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:32:43.280032Z","iopub.execute_input":"2022-01-05T04:32:43.280456Z","iopub.status.idle":"2022-01-05T04:32:43.342427Z","shell.execute_reply.started":"2022-01-05T04:32:43.280426Z","shell.execute_reply":"2022-01-05T04:32:43.341075Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:31:33.224424Z","iopub.execute_input":"2022-01-05T04:31:33.224815Z","iopub.status.idle":"2022-01-05T04:31:33.275439Z","shell.execute_reply.started":"2022-01-05T04:31:33.224780Z","shell.execute_reply":"2022-01-05T04:31:33.274439Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"y_fit.unstack().unstack().unstack().unstack().unstack().unstack()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:45:19.184574Z","iopub.execute_input":"2022-01-05T04:45:19.185212Z","iopub.status.idle":"2022-01-05T04:45:19.237148Z","shell.execute_reply.started":"2022-01-05T04:45:19.185161Z","shell.execute_reply":"2022-01-05T04:45:19.236279Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:33:42.015034Z","iopub.execute_input":"2022-01-05T04:33:42.015354Z","iopub.status.idle":"2022-01-05T04:33:42.074251Z","shell.execute_reply.started":"2022-01-05T04:33:42.015321Z","shell.execute_reply":"2022-01-05T04:33:42.073359Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"families = y.columns[0:]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:39:43.146596Z","iopub.execute_input":"2022-01-05T04:39:43.146934Z","iopub.status.idle":"2022-01-05T04:39:43.152160Z","shell.execute_reply.started":"2022-01-05T04:39:43.146901Z","shell.execute_reply":"2022-01-05T04:39:43.151428Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"y_fit.unstack()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:49:48.218652Z","iopub.execute_input":"2022-01-05T04:49:48.219126Z","iopub.status.idle":"2022-01-05T04:49:48.266805Z","shell.execute_reply.started":"2022-01-05T04:49:48.219092Z","shell.execute_reply":"2022-01-05T04:49:48.265652Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"y_fit.unstack().unstack().unstack().unstack().unstack().unstack().loc(axis=1)[families]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:45:36.210132Z","iopub.execute_input":"2022-01-05T04:45:36.210466Z","iopub.status.idle":"2022-01-05T04:45:36.264186Z","shell.execute_reply.started":"2022-01-05T04:45:36.210432Z","shell.execute_reply":"2022-01-05T04:45:36.263190Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"\naxs = y.loc(axis=1)[families].plot(\n    subplots=True, sharex=True, figsize=(20, 16), **plot_params, alpha=0.5,\n)\n_ = y_fit.unstack().unstack().unstack().unstack().unstack().unstack().loc(axis=1)[families].plot(subplots=True, sharex=True, color='C0', ax=axs)\n_ = y_pred.unstack().unstack().unstack().unstack().unstack().unstack().loc(axis=1)[families].plot(subplots=True, sharex=True, color='C3', ax=axs)\nfor ax, family in zip(axs, families):\n    ax.legend([])\n    ax.set_ylabel(family)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T04:47:15.939864Z","iopub.execute_input":"2022-01-05T04:47:15.940203Z","iopub.status.idle":"2022-01-05T04:47:24.773494Z","shell.execute_reply.started":"2022-01-05T04:47:15.940172Z","shell.execute_reply":"2022-01-05T04:47:24.772279Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2022-01-05T03:36:04.530674Z","iopub.status.idle":"2022-01-05T03:36:04.530990Z","shell.execute_reply.started":"2022-01-05T03:36:04.530820Z","shell.execute_reply":"2022-01-05T03:36:04.530842Z"},"trusted":true},"execution_count":null,"outputs":[]}]}